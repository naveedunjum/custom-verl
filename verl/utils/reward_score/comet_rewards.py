import re
from typing import Optional

# ---------------------------------------------------------------------------
# 0.  Regex for tag extraction  (identical to bleu_reward.py)
# ---------------------------------------------------------------------------

_TRANSLATE_RE = re.compile(r"<translate>(.*?)</translate>", re.DOTALL)


# ---------------------------------------------------------------------------
# 1.  Lazy model singletons
# ---------------------------------------------------------------------------

_comet_model = None  # reference-based
_cometkiwi_model = None  # reference-free


def _get_comet_model(model_path: str = "Unbabel/wmt22-comet-da"):
    """
    Load (or return cached) reference-based COMET model.

    Called once per worker process on the first scoring request.
    Subsequent calls return the already-loaded model instantly.

    The model is explicitly moved to torch.cuda.current_device() so that VERL's
    worker-level GPU assignment is respected. predict() is then called with
    gpus=0 to prevent COMET from re-managing device placement internally.

    Args:
        model_path: HuggingFace model ID or local checkpoint path.
                    Override via the `comet_model_path` key in `extra_info`
                    if you want per-run control without code changes.

    Returns:
        Loaded COMET model instance, already on the correct device.
    """
    global _comet_model
    if _comet_model is None:
        import torch
        from comet import download_model, load_from_checkpoint

        _comet_model = load_from_checkpoint(download_model(model_path))
        _comet_model = _comet_model.to(torch.cuda.current_device())
    return _comet_model


def _get_cometkiwi_model(model_path: str = "Unbabel/wmt23-cometkiwi-da-xl"):
    """
    Load (or return cached) reference-free COMETKiwi model.

    Same GPU placement logic as _get_comet_model: moved to current_device
    at load time, predict() called with gpus=0.

    Args:
        model_path: HuggingFace model ID or local checkpoint path.

    Returns:
        Loaded COMETKiwi model instance, already on the correct device.
    """
    global _cometkiwi_model
    if _cometkiwi_model is None:
        import torch
        from comet import download_model, load_from_checkpoint

        _cometkiwi_model = load_from_checkpoint(download_model(model_path))
        _cometkiwi_model = _cometkiwi_model.to(torch.cuda.current_device())
    return _cometkiwi_model


# ---------------------------------------------------------------------------
# 2.  Tag extraction  (same logic as bleu_reward.py)
# ---------------------------------------------------------------------------


def _extract_translation(model_output: str) -> Optional[str]:
    """
    Extract the hypothesis from the last <translate>...</translate> block.

    Takes the *last* match so that if the model echoes the tag inside its
    <think> trace, we always score the intended final answer.

    Args:
        model_output: Full raw string generated by the model.

    Returns:
        Extracted hypothesis string, or None if no valid tag is found.
    """
    matches = _TRANSLATE_RE.findall(model_output)
    if not matches:
        return None
    return matches[-1].strip()


# ---------------------------------------------------------------------------
# 3.  Format penalty  (mirrors bleu_reward.py)
# ---------------------------------------------------------------------------


def _format_penalty(model_output: str) -> float:
    """
    Compute a format penalty based on tag presence and content.

    Returns:
        0.0  if a non-empty <translate> block is present  (no penalty)
       -0.2  if the tag exists but its content is empty
       -0.5  if no <translate> tag is found at all
    """
    matches = _TRANSLATE_RE.findall(model_output)
    if not matches:
        return -0.5
    if not matches[-1].strip():
        return -0.2
    return 0.0


# ---------------------------------------------------------------------------
# 4.  Core COMET scoring helpers
# ---------------------------------------------------------------------------


def _score_comet(
    source: str,
    hypothesis: str,
    reference: str,
    model_path: str = "Unbabel/wmt22-comet-da",
    batch_size: int = 8,
) -> float:
    """
    Score a single (source, hypothesis, reference) triple with reference-based COMET.

    COMET's predict() is designed for batches; we wrap a single sample in a
    one-element list and extract the single score. For large-scale offline
    evaluation you would call predict() directly on a full batch instead.

    Args:
        source:      Source sentence (original language).
        hypothesis:  Model translation to evaluate.
        reference:   Ground-truth reference translation.
        model_path:  COMET checkpoint to use.
        batch_size:  Batch size passed to predict() (only affects throughput
                     when called in bulk; no effect for a single sample).

    Returns:
        COMET score, typically in [0, 1] for modern checkpoints.
    """
    model = _get_comet_model(model_path)
    data = [{"src": source, "mt": hypothesis, "ref": reference}]
    output = model.predict(data, batch_size=batch_size, gpus=0)
    return float(output.scores[0])


def _score_cometkiwi(
    source: str,
    hypothesis: str,
    model_path: str = "Unbabel/wmt23-cometkiwi-da-xl",
    batch_size: int = 8,
) -> float:
    """
    Score a single (source, hypothesis) pair with reference-free COMETKiwi.

    Args:
        source:      Source sentence.
        hypothesis:  Model translation to evaluate.
        model_path:  COMETKiwi checkpoint to use.
        batch_size:  Passed to predict().

    Returns:
        COMETKiwi quality estimate, typically in [0, 1].
    """
    model = _get_cometkiwi_model(model_path)
    data = [{"src": source, "mt": hypothesis}]
    output = model.predict(data, batch_size=batch_size, gpus=0)
    return float(output.scores[0])


# ---------------------------------------------------------------------------
# 5.  Public reward entry points  (called from __init__.py dispatcher)
# ---------------------------------------------------------------------------


def compute_score(
    data_source: str,
    solution_str: str,
    ground_truth: dict,
    extra_info: Optional[dict] = None,
) -> float:
    """
    Reference-based COMET reward.

    Expected keys in `ground_truth`:
        'tgt_text'  : reference translation string  (required)
        'src_text'  : source sentence               (required)

    Optional keys in `extra_info`:
        'comet_model_path' : override the default COMET checkpoint path

    Format validation mirrors bleu_reward.py:
        -0.5  penalty if no <translate> tag
        -0.2  penalty if tag is present but empty
         0.0  no format penalty if tag is present and non-empty

    Final reward = COMET score (in [0,1]) + format_penalty, clipped to [-1, 1].

    Args:
        data_source:  Dataset identifier string (used for routing; not used
                      for scoring logic, but available for future branching).
        solution_str: Full raw model output for one sample.
        ground_truth: Dict with at least 'src_text' and 'tgt_text'.
        extra_info:   Optional metadata dict.

    Returns:
        Float reward in [-1, 1].
    """
    reference = ground_truth.get("tgt_text", "")
    source = ground_truth.get("src_text", "")

    if not reference or not source:
        return 0.0

    model_path = (extra_info or {}).get("comet_model_path", "Unbabel/wmt22-comet-da")

    penalty = _format_penalty(solution_str)

    hypothesis = _extract_translation(solution_str)
    if not hypothesis:
        # No translatable content found â€” return format penalty only
        return float(max(-1.0, penalty))

    comet_score = _score_comet(
        source=source,
        hypothesis=hypothesis,
        reference=reference,
        model_path=model_path,
    )

    total = comet_score + penalty
    return float(max(-1.0, min(1.0, total)))


def compute_score_kiwi(
    data_source: str,
    solution_str: str,
    ground_truth: dict,
    extra_info: Optional[dict] = None,
) -> float:
    """
    Reference-free COMETKiwi reward.

    Expected keys in `ground_truth`:
        'src_text'  : source sentence  (required)
        'tgt_text'  : not used for scoring, but kept for API consistency

    Optional keys in `extra_info`:
        'cometkiwi_model_path' : override the default COMETKiwi checkpoint path

    Format penalty and clipping are identical to `compute_score`.

    Args:
        data_source:  Dataset identifier string.
        solution_str: Full raw model output for one sample.
        ground_truth: Dict with at least 'src_text'.
        extra_info:   Optional metadata dict.

    Returns:
        Float reward in [-1, 1].
    """
    source = ground_truth.get("src_text", "")

    if not source:
        return 0.0

    model_path = (extra_info or {}).get("cometkiwi_model_path", "Unbabel/wmt23-cometkiwi-da-xl")

    penalty = _format_penalty(solution_str)

    hypothesis = _extract_translation(solution_str)
    if not hypothesis:
        return float(max(-1.0, penalty))

    kiwi_score = _score_cometkiwi(
        source=source,
        hypothesis=hypothesis,
        model_path=model_path,
    )

    total = kiwi_score + penalty
    return float(max(-1.0, min(1.0, total)))
